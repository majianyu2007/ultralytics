#!/usr/bin/env python3
"""
YOLOv26 åŒæµæ¨¡å‹æµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨ä¿®æ”¹åçš„ultralyticsè¿›è¡ŒåŒæµï¼ˆRGB + IRï¼‰ç›®æ ‡æ£€æµ‹çš„è®­ç»ƒå’Œæ¨ç†ã€‚

ä½¿ç”¨æ–¹æ³•ï¼š
1. å‡†å¤‡æ•°æ®é›†ï¼ˆRGBå’ŒIRå›¾åƒå¯¹ï¼‰
2. ä¿®æ”¹æ•°æ®é…ç½®æ–‡ä»¶è·¯å¾„
3. è¿è¡Œæ­¤è„šæœ¬

ä½œè€…: Claude Code
"""

import os
import sys
import torch
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from ultralytics.models.yolo.detect.dual_train import DualStreamDetectionTrainer
from ultralytics.nn.dual_tasks import DualStreamDetectionModel
from ultralytics.data.dual_dataset import DualStreamYOLODataset
from ultralytics.utils import LOGGER


def create_dummy_data(output_dir="dummy_dual_data", num_images=10):
    """
    åˆ›å»ºè™šæ‹ŸåŒæµæ•°æ®ç”¨äºæµ‹è¯•

    Args:
        output_dir (str): è¾“å‡ºç›®å½•
        num_images (int): ç”Ÿæˆçš„å›¾åƒå¯¹æ•°é‡

    Returns:
        str: æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
    """
    import cv2
    import yaml

    output_path = Path(output_dir)

    # åˆ›å»ºç›®å½•ç»“æ„
    rgb_train_dir = output_path / "rgb" / "train"
    ir_train_dir = output_path / "ir" / "train"
    rgb_val_dir = output_path / "rgb" / "val"
    ir_val_dir = output_path / "ir" / "val"
    labels_train_dir = output_path / "labels" / "train"
    labels_val_dir = output_path / "labels" / "val"

    for dir_path in [rgb_train_dir, ir_train_dir, rgb_val_dir, ir_val_dir, labels_train_dir, labels_val_dir]:
        dir_path.mkdir(parents=True, exist_ok=True)

    LOGGER.info(f"åˆ›å»ºè™šæ‹Ÿæ•°æ®é›†åœ¨: {output_path}")

    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    for i in range(num_images):
        # åˆ›å»ºè™šæ‹ŸRGBå›¾åƒ (640x640, 3é€šé“)
        rgb_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        cv2.imwrite(str(rgb_train_dir / f"image_{i:03d}.jpg"), rgb_img)
        cv2.imwrite(str(rgb_val_dir / f"image_{i:03d}.jpg"), rgb_img)

        # åˆ›å»ºè™šæ‹ŸIRå›¾åƒ (640x640, 3é€šé“, ä½†å†…å®¹ä¸åŒ)
        ir_img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
        cv2.imwrite(str(ir_train_dir / f"image_{i:03d}.jpg"), ir_img)
        cv2.imwrite(str(ir_val_dir / f"image_{i:03d}.jpg"), ir_img)

        # åˆ›å»ºè™šæ‹Ÿæ ‡ç­¾æ–‡ä»¶
        label_content = "0 0.5 0.5 0.2 0.3\n1 0.3 0.7 0.15 0.25\n"  # class x y w h (normalized)
        with open(labels_train_dir / f"image_{i:03d}.txt", 'w') as f:
            f.write(label_content)
        with open(labels_val_dir / f"image_{i:03d}.txt", 'w') as f:
            f.write(label_content)

    # åˆ›å»ºæ•°æ®é›†é…ç½®æ–‡ä»¶
    dataset_config = {
        'rgb_train': str(rgb_train_dir),
        'rgb_val': str(rgb_val_dir),
        'ir_train': str(ir_train_dir),
        'ir_val': str(ir_val_dir),
        'train': str(rgb_train_dir),
        'val': str(rgb_val_dir),
        'labels_train': str(labels_train_dir),
        'labels_val': str(labels_val_dir),
        'nc': 2,  # 2ä¸ªç±»åˆ«ç”¨äºæµ‹è¯•
        'names': ['person', 'vehicle']
    }

    config_path = output_path / "dataset_config.yaml"
    with open(config_path, 'w') as f:
        yaml.dump(dataset_config, f, default_flow_style=False)

    LOGGER.info(f"æ•°æ®é›†é…ç½®ä¿å­˜åˆ°: {config_path}")
    return str(config_path)


def test_dual_stream_dataset():
    """æµ‹è¯•åŒæµæ•°æ®é›†åŠ è½½"""
    LOGGER.info("=" * 60)
    LOGGER.info("æµ‹è¯•1: åŒæµæ•°æ®é›†åŠ è½½")
    LOGGER.info("=" * 60)

    try:
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        config_path = create_dummy_data()

        # æµ‹è¯•æ•°æ®é›†åŠ è½½
        dataset = DualStreamYOLODataset(
            rgb_img_path="dummy_dual_data/rgb/train",
            ir_img_path="dummy_dual_data/ir/train",
            imgsz=640,
            augment=False,
            label_path="dummy_dual_data/labels/train",
        )

        LOGGER.info(f"æ•°æ®é›†å¤§å°: {len(dataset)}")

        # æµ‹è¯•è·å–ä¸€ä¸ªæ ·æœ¬
        sample = dataset[0]
        img_tensor = sample['img']

        LOGGER.info(f"è¾“å…¥å›¾åƒshape: {img_tensor.shape}")  # åº”è¯¥æ˜¯ (6, 640, 640)
        LOGGER.info(f"å‰3é€šé“ (RGB) èŒƒå›´: [{img_tensor[:3].min():.3f}, {img_tensor[:3].max():.3f}]")
        LOGGER.info(f"å3é€šé“ (IR) èŒƒå›´: [{img_tensor[3:].min():.3f}, {img_tensor[3:].max():.3f}]")

        if img_tensor.shape[0] == 6:
            LOGGER.info("âœ… åŒæµæ•°æ®é›†åŠ è½½æˆåŠŸï¼")
            return True
        else:
            LOGGER.error(f"âŒ é”™è¯¯ï¼šæœŸæœ›6é€šé“ï¼Œä½†å¾—åˆ°{img_tensor.shape[0]}é€šé“")
            return False

    except Exception as e:
        LOGGER.error(f"âŒ åŒæµæ•°æ®é›†æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_dual_stream_model():
    """æµ‹è¯•åŒæµæ¨¡å‹"""
    LOGGER.info("=" * 60)
    LOGGER.info("æµ‹è¯•2: åŒæµæ¨¡å‹æ¨ç†")
    LOGGER.info("=" * 60)

    try:
        # åˆ›å»ºåŒæµæ¨¡å‹
        model = DualStreamDetectionModel(cfg="ultralytics/cfg/models/26/yolo26.yaml", ch=6, nc=2)
        model.eval()

        # åˆ›å»ºè™šæ‹Ÿè¾“å…¥ (batch_size=2, channels=6, height=640, width=640)
        dummy_input = torch.randn(2, 6, 640, 640)

        LOGGER.info(f"è¾“å…¥shape: {dummy_input.shape}")

        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            output = model(dummy_input)

        LOGGER.info(f"è¾“å‡ºç±»å‹: {type(output)}")
        if isinstance(output, torch.Tensor):
            LOGGER.info(f"è¾“å‡ºshape: {output.shape}")
        elif isinstance(output, (list, tuple)):
            LOGGER.info(f"è¾“å‡ºæ•°é‡: {len(output)}")
            for i, out in enumerate(output):
                if isinstance(out, torch.Tensor):
                    LOGGER.info(f"è¾“å‡º {i} shape: {out.shape}")

        LOGGER.info("âœ… åŒæµæ¨¡å‹æ¨ç†æˆåŠŸï¼")
        return True

    except Exception as e:
        LOGGER.error(f"âŒ åŒæµæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_dual_stream_training():
    """æµ‹è¯•åŒæµæ¨¡å‹è®­ç»ƒ"""
    LOGGER.info("=" * 60)
    LOGGER.info("æµ‹è¯•3: åŒæµæ¨¡å‹è®­ç»ƒ")
    LOGGER.info("=" * 60)

    try:
        # åˆ›å»ºè™šæ‹Ÿæ•°æ®
        config_path = create_dummy_data()

        # é…ç½®è®­ç»ƒå‚æ•°
        args = {
            'model': 'ultralytics/cfg/models/26/yolo26.yaml',
            'data': config_path,
            'epochs': 2,  # åªè®­ç»ƒ2ä¸ªepochç”¨äºæµ‹è¯•
            'batch': 2,   # å°æ‰¹æ¬¡
            'imgsz': 640,
            'save': True,
            'verbose': True,
            'device': 'cpu',  # ä½¿ç”¨CPUé¿å…GPUå†…å­˜é—®é¢˜
        }

        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = DualStreamDetectionTrainer(overrides=args)

        LOGGER.info("å¼€å§‹è®­ç»ƒ...")

        # è¿è¡Œè®­ç»ƒï¼ˆåªè®­ç»ƒå‡ æ­¥ç”¨äºæµ‹è¯•ï¼‰
        trainer.train()

        LOGGER.info("âœ… åŒæµæ¨¡å‹è®­ç»ƒæˆåŠŸï¼")
        return True

    except Exception as e:
        LOGGER.error(f"âŒ åŒæµè®­ç»ƒæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_data_splitting():
    """æµ‹è¯•6é€šé“æ•°æ®çš„åˆ†ç¦»"""
    LOGGER.info("=" * 60)
    LOGGER.info("æµ‹è¯•4: 6é€šé“æ•°æ®åˆ†ç¦»")
    LOGGER.info("=" * 60)

    try:
        # åˆ›å»º6é€šé“æµ‹è¯•æ•°æ®
        batch_size, height, width = 4, 640, 640
        test_data = torch.randn(batch_size, 6, height, width)

        # åˆ†ç¦»RGBå’ŒIR
        rgb_data = test_data[:, :3, :, :]
        ir_data = test_data[:, 3:, :, :]

        LOGGER.info(f"åŸå§‹æ•°æ® shape: {test_data.shape}")
        LOGGER.info(f"RGBæ•°æ® shape: {rgb_data.shape}")
        LOGGER.info(f"IRæ•°æ® shape: {ir_data.shape}")

        # éªŒè¯åˆ†ç¦»æ˜¯å¦æ­£ç¡®
        assert rgb_data.shape == (batch_size, 3, height, width), f"RGB shapeé”™è¯¯: {rgb_data.shape}"
        assert ir_data.shape == (batch_size, 3, height, width), f"IR shapeé”™è¯¯: {ir_data.shape}"

        # éªŒè¯æ•°æ®ä¸€è‡´æ€§
        reconstructed = torch.cat([rgb_data, ir_data], dim=1)
        assert torch.allclose(test_data, reconstructed), "æ•°æ®é‡æ„ä¸ä¸€è‡´"

        LOGGER.info("âœ… 6é€šé“æ•°æ®åˆ†ç¦»æµ‹è¯•æˆåŠŸï¼")
        return True

    except Exception as e:
        LOGGER.error(f"âŒ æ•°æ®åˆ†ç¦»æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    LOGGER.info("å¼€å§‹YOLOv26åŒæµæ¨¡å‹æµ‹è¯•")
    LOGGER.info("=" * 80)

    test_results = []

    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    test_results.append(("æ•°æ®åˆ†ç¦»æµ‹è¯•", test_data_splitting()))
    test_results.append(("åŒæµæ•°æ®é›†æµ‹è¯•", test_dual_stream_dataset()))
    test_results.append(("åŒæµæ¨¡å‹æµ‹è¯•", test_dual_stream_model()))
    test_results.append(("åŒæµè®­ç»ƒæµ‹è¯•", test_dual_stream_training()))

    # æ±‡æ€»ç»“æœ
    LOGGER.info("=" * 80)
    LOGGER.info("æµ‹è¯•ç»“æœæ±‡æ€»:")
    LOGGER.info("=" * 80)

    passed = 0
    total = len(test_results)

    for test_name, result in test_results:
        status = "âœ… PASSED" if result else "âŒ FAILED"
        LOGGER.info(f"{test_name}: {status}")
        if result:
            passed += 1

    LOGGER.info("=" * 80)
    LOGGER.info(f"æ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        LOGGER.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼YOLOv26åŒæµæ”¹é€ æˆåŠŸï¼")

        # è¾“å‡ºä½¿ç”¨è¯´æ˜
        LOGGER.info("\n" + "=" * 80)
        LOGGER.info("ä½¿ç”¨è¯´æ˜:")
        LOGGER.info("=" * 80)
        LOGGER.info("1. å‡†å¤‡ä½ çš„åŒæµæ•°æ®é›†ï¼ˆRGB + IRå›¾åƒå¯¹ï¼‰")
        LOGGER.info("2. åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶ï¼Œå‚è€ƒ dual_dataset_example.yaml")
        LOGGER.info("3. ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®­ç»ƒ:")
        LOGGER.info("   python -c \"from dual_train import DualStreamDetectionTrainer; trainer = DualStreamDetectionTrainer(overrides={'model': 'ultralytics/cfg/models/26/yolo26.yaml', 'data': 'your_data.yaml', 'epochs': 100}); trainer.train()\"")
        LOGGER.info("4. è®­ç»ƒå®Œæˆåï¼Œæ¨¡å‹å°†è‡ªåŠ¨ä¿å­˜")

    else:
        LOGGER.error(f"âŒ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
