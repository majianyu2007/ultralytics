# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

"""
åŒæµYOLOæ£€æµ‹æ¨¡å‹

è¿™ä¸ªæ¨¡å—å®ç°äº†æ”¯æŒåŒæµè¾“å…¥ï¼ˆRGB + IRï¼‰çš„YOLOæ£€æµ‹æ¨¡å‹æ¶æ„
"""

import torch
import torch.nn as nn
from ultralytics.nn.tasks import DetectionModel, BaseModel, yaml_model_load, attempt_load_weights
from ultralytics.utils import LOGGER
from ultralytics.nn.modules import Conv, Concat


class DualStreamDetectionModel(DetectionModel):
    """
    åŒæµYOLOæ£€æµ‹æ¨¡å‹

    æ”¯æŒRGBå’ŒIRå›¾åƒçš„åŒæµè¾“å…¥ï¼Œå†…éƒ¨å°†6é€šé“è¾“å…¥åˆ†ç¦»ä¸ºä¸¤ä¸ª3é€šé“æµè¿›è¡Œå¤„ç†ï¼Œ
    ç„¶åé€šè¿‡èåˆæœºåˆ¶ç»“åˆä¸¤ä¸ªæµçš„ç‰¹å¾è¿›è¡Œæœ€ç»ˆæ£€æµ‹ã€‚

    ä¸»è¦ç‰¹ç‚¹ï¼š
    - æ¥å—6é€šé“è¾“å…¥ï¼ˆRGB 3é€šé“ + IR 3é€šé“ï¼‰
    - å†…éƒ¨åˆ†ç¦»ä¸ºä¸¤ä¸ªç‹¬ç«‹çš„3é€šé“å¤„ç†æµ
    - æ”¯æŒå¤šå±‚ç‰¹å¾èåˆ
    - å…¼å®¹æ ‡å‡†YOLOæ£€æµ‹å¤´
    """

    def __init__(self, cfg="yolo26n.yaml", ch=6, nc=None, verbose=True):
        """
        åˆå§‹åŒ–åŒæµYOLOæ£€æµ‹æ¨¡å‹

        Args:
            cfg (str | dict): æ¨¡å‹é…ç½®æ–‡ä»¶æˆ–å­—å…¸
            ch (int): è¾“å…¥é€šé“æ•°ï¼Œé»˜è®¤6ï¼ˆRGB 3 + IR 3ï¼‰
            nc (int): ç±»åˆ«æ•°
            verbose (bool): æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
        # å¼ºåˆ¶è®¾ç½®ä¸º6é€šé“è¾“å…¥
        if ch != 6:
            LOGGER.warning(f"åŒæµæ¨¡å‹è¦æ±‚6é€šé“è¾“å…¥ (RGB 3 + IR 3), ä½†æ”¶åˆ° ch={ch}, è‡ªåŠ¨è®¾ç½®ä¸º6")
            ch = 6

        # åˆå§‹åŒ–åŸºç¡€æ£€æµ‹æ¨¡å‹
        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)

        # æ ‡è®°ä¸ºåŒæµæ¨¡å‹
        self.is_dual_stream = True

    def predict(self, x, profile=False, visualize=False, augment=False, embed=None):
        """
        åŒæµé¢„æµ‹å‰å‘ä¼ æ’­

        Args:
            x (torch.Tensor): è¾“å…¥å¼ é‡ï¼Œshapeä¸º (batch_size, 6, height, width)
            profile (bool): æ˜¯å¦æ€§èƒ½åˆ†æ
            visualize (bool): æ˜¯å¦å¯è§†åŒ–
            augment (bool): æ˜¯å¦æ•°æ®å¢å¼º
            embed (list): ç‰¹å¾åµŒå…¥å±‚ç´¢å¼•

        Returns:
            torch.Tensor: æ£€æµ‹ç»“æœ
        """
        # éªŒè¯è¾“å…¥é€šé“æ•°
        if x.shape[1] != 6:
            raise ValueError(f"åŒæµæ¨¡å‹è¦æ±‚6é€šé“è¾“å…¥ï¼Œä½†æ”¶åˆ° {x.shape[1]} é€šé“")

        # åˆ†ç¦»RGBå’ŒIRæµ
        rgb_stream = x[:, :3, :, :]  # å‰3é€šé“ (RGB)
        ir_stream = x[:, 3:, :, :]   # å3é€šé“ (IR)

        if augment:
            return self._predict_dual_stream_augment(rgb_stream, ir_stream, profile, visualize, embed)
        else:
            return self._predict_dual_stream_once(rgb_stream, ir_stream, profile, visualize, embed)

    def _predict_dual_stream_once(self, rgb_x, ir_x, profile=False, visualize=False, embed=None):
        """
        åŒæµå•æ¬¡å‰å‘ä¼ æ’­

        Args:
            rgb_x (torch.Tensor): RGBæµè¾“å…¥ (batch_size, 3, height, width)
            ir_x (torch.Tensor): IRæµè¾“å…¥ (batch_size, 3, height, width)

        Returns:
            torch.Tensor: ç½‘ç»œè¾“å‡º
        """
        y_rgb, y_ir, dt = [], [], []

        # éå†æ¨¡å‹çš„æ¯ä¸€å±‚
        for i, m in enumerate(self.model):
            layer_name = getattr(m, 'layer_name', f'layer_{i}')

            # æ ¹æ®å±‚çš„é…ç½®å†³å®šå¤„ç†å“ªä¸ªæµ
            if hasattr(m, 'dual_stream_mode'):
                mode = m.dual_stream_mode
            else:
                # é»˜è®¤é€»è¾‘ï¼šæ ¹æ®å±‚çš„ä½ç½®å’Œç±»å‹åˆ¤æ–­å¤„ç†æ¨¡å¼
                mode = self._get_layer_mode(i, m)

            if profile:
                from ultralytics.utils.torch_utils import time_sync
                c = m == self.model[-1]  # is final layer
                o = torch.jit.trace(m, (rgb_x.copy() if c else rgb_x,), strict=False)[0].flops / 1E9 * 2 if profile else 0
                t = time_sync()
                for _ in range(10):
                    _ = m(rgb_x.copy() if c else rgb_x)
                dt.append((time_sync() - t) * 100)
                LOGGER.info(f'{dt[-1]:10.2f} {o:10.2f} {m.np:10.0f}  {m.type}')

            # æ ¹æ®æ¨¡å¼å¤„ç†æµ
            if mode == 'rgb_only':
                # åªå¤„ç†RGBæµ
                if m.f != -1:  # ä¸æ˜¯ä»ä¸Šä¸€å±‚
                    rgb_x = y_rgb[m.f] if isinstance(m.f, int) else [rgb_x if j == -1 else y_rgb[j] for j in m.f]
                rgb_x = m(rgb_x)
                y_rgb.append(rgb_x if m.i in self.save else None)

            elif mode == 'ir_only':
                # åªå¤„ç†IRæµ
                if m.f != -1:
                    ir_x = y_ir[m.f] if isinstance(m.f, int) else [ir_x if j == -1 else y_ir[j] for j in m.f]
                ir_x = m(ir_x)
                y_ir.append(ir_x if m.i in self.save else None)

            elif mode == 'fusion':
                # èåˆä¸¤ä¸ªæµ
                if hasattr(m, 'forward_dual'):
                    # è‡ªå®šä¹‰åŒæµå‰å‘ä¼ æ’­
                    fused_output = m.forward_dual(rgb_x, ir_x)
                    if isinstance(fused_output, (list, tuple)):
                        rgb_x, ir_x = fused_output[0], fused_output[1]
                    else:
                        rgb_x = ir_x = fused_output
                else:
                    # é»˜è®¤èåˆï¼šç®€å•ç›¸åŠ 
                    fused = (rgb_x + ir_x) / 2
                    rgb_x = ir_x = fused

                y_rgb.append(rgb_x if m.i in self.save else None)
                y_ir.append(ir_x if m.i in self.save else None)

            elif mode == 'final':
                # æœ€ç»ˆå±‚ï¼Œåˆå¹¶ä¸¤ä¸ªæµ
                if hasattr(m, 'forward_dual'):
                    combined_x = m.forward_dual(rgb_x, ir_x)
                else:
                    # åœ¨é€šé“ç»´åº¦æ‹¼æ¥ä¸¤ä¸ªæµ
                    combined_x = torch.cat([rgb_x, ir_x], dim=1)
                    combined_x = m(combined_x)

                y_rgb.append(combined_x if m.i in self.save else None)
                y_ir.append(combined_x if m.i in self.save else None)
                return combined_x

        # å¦‚æœæ²¡æœ‰finalå±‚ï¼Œé»˜è®¤åˆå¹¶è¾“å‡º
        if hasattr(self.model[-1], 'forward_dual'):
            return self.model[-1].forward_dual(rgb_x, ir_x)
        else:
            # ç®€å•èåˆç­–ç•¥
            return (rgb_x + ir_x) / 2

    def _get_layer_mode(self, layer_idx, module):
        """
        æ ¹æ®å±‚ç´¢å¼•å’Œæ¨¡å—ç±»å‹ç¡®å®šå¤„ç†æ¨¡å¼

        Args:
            layer_idx (int): å±‚ç´¢å¼•
            module (nn.Module): æ¨¡å—

        Returns:
            str: å¤„ç†æ¨¡å¼ ('rgb_only', 'ir_only', 'fusion', 'final')
        """
        # è¿™é‡Œå¯ä»¥æ ¹æ®å…·ä½“çš„æ¨¡å‹æ¶æ„æ¥å®šä¹‰è§„åˆ™
        # ç¤ºä¾‹è§„åˆ™ï¼š

        # æ£€æµ‹å¤´é€šå¸¸æ˜¯æœ€åçš„å±‚
        if isinstance(module, (Detect, YOLOEDetect, v10Detect, Segment, Pose, OBB)):
            return 'final'

        # å‰å‡ å±‚åˆ†åˆ«å¤„ç†RGBå’ŒIR
        if layer_idx < len(self.model) // 4:
            return 'rgb_only' if layer_idx % 2 == 0 else 'ir_only'

        # ä¸­é—´å±‚è¿›è¡Œèåˆ
        elif layer_idx < len(self.model) * 3 // 4:
            return 'fusion'

        # åé¢çš„å±‚ç»§ç»­èåˆ
        else:
            return 'fusion'

    def _predict_dual_stream_augment(self, rgb_x, ir_x, profile=False, visualize=False, embed=None):
        """
        åŒæµå¢å¼ºæ¨ç†

        Args:
            rgb_x (torch.Tensor): RGBæµè¾“å…¥
            ir_x (torch.Tensor): IRæµè¾“å…¥

        Returns:
            torch.Tensor: å¢å¼ºæ¨ç†ç»“æœ
        """
        # å®ç°åŒæµçš„å¢å¼ºæ¨ç†
        img_size = rgb_x.shape[-2:]  # height, width
        s = [1, 0.83, 0.67]  # scales
        f = [None, 3, None]  # flips (2-ud, 3-lr)
        y = []  # outputs

        for si, fi in zip(s, f):
            # å¯¹RGBå’ŒIRåº”ç”¨ç›¸åŒçš„å˜æ¢
            xi_rgb = scale_img(rgb_x.flip(fi) if fi else rgb_x, si)
            xi_ir = scale_img(ir_x.flip(fi) if fi else ir_x, si)

            yi = self._predict_dual_stream_once(xi_rgb, xi_ir, profile, visualize, embed)
            yi = self._descale_pred(yi, fi, si, img_size)
            y.append(yi)

        y = self._clip_augmented(y)  # clip augmented tails
        return torch.cat(y, 1)


class DualStreamFusion(nn.Module):
    """
    åŒæµèåˆæ¨¡å—

    å¯ä»¥ä½œä¸ºç½‘ç»œä¸­çš„èåˆå±‚ï¼Œå°†RGBå’ŒIRä¸¤ä¸ªæµçš„ç‰¹å¾è¿›è¡Œèåˆ
    """

    def __init__(self, channels, fusion_type='concat'):
        """
        åˆå§‹åŒ–èåˆæ¨¡å—

        Args:
            channels (int): è¾“å…¥é€šé“æ•°
            fusion_type (str): èåˆç±»å‹ ('concat', 'add', 'attention')
        """
        super().__init__()
        self.fusion_type = fusion_type
        self.channels = channels

        if fusion_type == 'concat':
            self.conv = Conv(channels * 2, channels, 1)
        elif fusion_type == 'attention':
            self.attention = nn.MultiheadAttention(channels, 8)
            self.norm = nn.LayerNorm(channels)

    def forward_dual(self, rgb_feat, ir_feat):
        """
        åŒæµèåˆå‰å‘ä¼ æ’­

        Args:
            rgb_feat (torch.Tensor): RGBç‰¹å¾
            ir_feat (torch.Tensor): IRç‰¹å¾

        Returns:
            tuple: èåˆåçš„(rgb_feat, ir_feat)
        """
        if self.fusion_type == 'concat':
            # æ‹¼æ¥èåˆ
            fused = torch.cat([rgb_feat, ir_feat], dim=1)
            fused = self.conv(fused)
            return fused, fused

        elif self.fusion_type == 'add':
            # ç›¸åŠ èåˆ
            fused = (rgb_feat + ir_feat) / 2
            return fused, fused

        elif self.fusion_type == 'attention':
            # æ³¨æ„åŠ›èåˆ
            B, C, H, W = rgb_feat.shape
            rgb_flat = rgb_feat.view(B, C, H*W).permute(2, 0, 1)  # (H*W, B, C)
            ir_flat = ir_feat.view(B, C, H*W).permute(2, 0, 1)    # (H*W, B, C)

            # äº¤å‰æ³¨æ„åŠ›
            rgb_attended, _ = self.attention(rgb_flat, ir_flat, ir_flat)
            ir_attended, _ = self.attention(ir_flat, rgb_flat, rgb_flat)

            # æ¢å¤å½¢çŠ¶
            rgb_out = rgb_attended.permute(1, 2, 0).view(B, C, H, W)
            ir_out = ir_attended.permute(1, 2, 0).view(B, C, H, W)

            # æ®‹å·®è¿æ¥
            rgb_out = self.norm(rgb_out.view(B, C, -1)).view(B, C, H, W) + rgb_feat
            ir_out = self.norm(ir_out.view(B, C, -1)).view(B, C, H, W) + ir_feat

            return rgb_out, ir_out

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èåˆç±»å‹: {self.fusion_type}")

    def forward(self, x):
        """æ ‡å‡†å‰å‘ä¼ æ’­ï¼ˆç”¨äºéåŒæµåœºæ™¯ï¼‰"""
        return x


# æ³¨å†ŒåŒæµèåˆæ¨¡å—
import sys
from ultralytics.nn.modules import Conv, Concat, Detect
if 'DualStreamFusion' not in globals():
    globals()['DualStreamFusion'] = DualStreamFusion