# Ultralytics ğŸš€ AGPL-3.0 License - https://ultralytics.com/license

from __future__ import annotations

import json
from collections import defaultdict
from itertools import repeat
from multiprocessing.pool import ThreadPool
from pathlib import Path
from typing import Any

import cv2
import numpy as np
import torch
from PIL import Image
from torch.utils.data import ConcatDataset

from ultralytics.utils import LOCAL_RANK, LOGGER, NUM_THREADS, TQDM, colorstr
from ultralytics.utils.instance import Instances
from ultralytics.utils.ops import resample_segments, segments2boxes
from ultralytics.utils.torch_utils import TORCHVISION_0_18

from .augment import (
    Compose,
    Format,
    LetterBox,
    RandomLoadText,
    classify_augmentations,
    classify_transforms,
    v8_transforms,
)
from .base import BaseDataset
from .converter import merge_multi_segment
from .utils import (
    HELP_URL,
    check_file_speeds,
    get_hash,
    img2label_paths,
    load_dataset_cache_file,
    save_dataset_cache_file,
    verify_image,
    verify_image_label,
)

# Ultralytics dataset *.cache version, >= 1.0.0 for Ultralytics YOLO models
DATASET_CACHE_VERSION = "1.0.3"


class DualStreamYOLODataset(BaseDataset):
    """
    åŒæµYOLOæ•°æ®é›†ç±»ï¼Œç”¨äºåŠ è½½RGBå’ŒIRï¼ˆçº¢å¤–ï¼‰å›¾åƒå¯¹è¿›è¡Œå¤šæ¨¡æ€ç›®æ ‡æ£€æµ‹

    è¯¥ç±»ç»§æ‰¿è‡ªBaseDatasetï¼Œå®ç°äº†åŒæµè¾“å…¥çš„æ•°æ®åŠ è½½ï¼Œå…¶ä¸­ï¼š
    - RGBå›¾åƒå’ŒIRå›¾åƒåˆ†åˆ«ä»ä¸åŒè·¯å¾„åŠ è½½
    - ä¸¤ç§å›¾åƒåœ¨é€šé“ç»´åº¦è¿›è¡Œæ‹¼æ¥ï¼ˆRGB: 3é€šé“ + IR: 3é€šé“ = 6é€šé“ï¼‰
    - æ”¯æŒYOLOæ ¼å¼çš„æ ‡ç­¾

    Attributes:
        rgb_img_path (str): RGBå›¾åƒè·¯å¾„
        ir_img_path (str): IRå›¾åƒè·¯å¾„
        im_files_rgb (list): RGBå›¾åƒæ–‡ä»¶åˆ—è¡¨
        im_files_ir (list): IRå›¾åƒæ–‡ä»¶åˆ—è¡¨
    """

    def __init__(
        self,
        rgb_img_path: str,
        ir_img_path: str,
        imgsz: int = 640,
        cache: bool = False,
        augment: bool = True,
        hyp: dict | None = None,
        prefix: str = "",
        rect: bool = False,
        batch_size: int | None = None,
        stride: int = 32,
        pad: float = 0.0,
        single_cls: bool = False,
        classes: list[str] | None = None,
    ):
        """
        åˆå§‹åŒ–åŒæµYOLOæ•°æ®é›†

        Args:
            rgb_img_path (str): RGBå›¾åƒè·¯å¾„
            ir_img_path (str): IRå›¾åƒè·¯å¾„
            imgsz (int): å›¾åƒå¤§å°
            cache (bool): æ˜¯å¦ç¼“å­˜
            augment (bool): æ˜¯å¦æ•°æ®å¢å¼º
            hyp (dict): è¶…å‚æ•°å­—å…¸
            prefix (str): æ—¥å¿—å‰ç¼€
            rect (bool): çŸ©å½¢è®­ç»ƒ
            batch_size (int): æ‰¹æ¬¡å¤§å°
            stride (int): æ¨¡å‹æ­¥é•¿
            pad (float): å¡«å……å€¼
            single_cls (bool): å•ç±»åˆ«æ¨¡å¼
            classes (list): ç±»åˆ«åˆ—è¡¨
        """
        self.rgb_img_path = rgb_img_path
        self.ir_img_path = ir_img_path

        # è·å–RGBå’ŒIRå›¾åƒæ–‡ä»¶åˆ—è¡¨
        self.im_files_rgb = self._get_image_files(rgb_img_path)
        self.im_files_ir = self._get_image_files(ir_img_path)

        # ç¡®ä¿RGBå’ŒIRå›¾åƒæ•°é‡ä¸€è‡´
        if len(self.im_files_rgb) != len(self.im_files_ir):
            raise ValueError(f"RGBå›¾åƒæ•°é‡({len(self.im_files_rgb)}) ä¸ IRå›¾åƒæ•°é‡({len(self.im_files_ir)}) ä¸åŒ¹é…")

        # ä½¿ç”¨RGBå›¾åƒè·¯å¾„ä½œä¸ºä¸»è·¯å¾„ï¼Œæ ‡ç­¾æ–‡ä»¶åŸºäºRGBå›¾åƒåç§°
        super().__init__(
            img_path=rgb_img_path,
            imgsz=imgsz,
            cache=cache,
            augment=augment,
            hyp=hyp,
            prefix=prefix,
            rect=rect,
            batch_size=batch_size,
            stride=stride,
            pad=pad,
            single_cls=single_cls,
            classes=classes,
        )

    def _get_image_files(self, img_path: str) -> list:
        """è·å–æŒ‡å®šè·¯å¾„ä¸‹çš„å›¾åƒæ–‡ä»¶åˆ—è¡¨"""
        try:
            f = []
            p = Path(img_path)
            if p.is_dir():  # å¦‚æœæ˜¯ç›®å½•
                f = list(p.rglob("*.*"))  # é€’å½’è·å–æ‰€æœ‰æ–‡ä»¶
                f = [str(x) for x in f if x.suffix.lower()[1:] in {"jpg", "jpeg", "png", "bmp", "tiff", "tif"}]
            elif p.is_file():  # å¦‚æœæ˜¯æ–‡ä»¶ï¼ˆåŒ…å«å›¾åƒè·¯å¾„åˆ—è¡¨ï¼‰
                with open(p) as file:
                    f = file.read().strip().splitlines()
                parent = str(p.parent) + "/"
                f = [x.replace("./", parent) if x.startswith("./") else x for x in f]
            return sorted(f)
        except Exception as e:
            raise FileNotFoundError(f"æ— æ³•ä» {img_path} åŠ è½½å›¾åƒ: {e}")

    def get_image_and_label(self, i: int):
        """
        è·å–ç´¢å¼•içš„RGBå›¾åƒã€IRå›¾åƒå’Œæ ‡ç­¾

        Args:
            i (int): å›¾åƒç´¢å¼•

        Returns:
            tuple: (rgb_image, ir_image, label_dict, image_path)
        """
        # åŠ è½½RGBå›¾åƒ
        rgb_img = self.load_image(i, rgb=True)

        # åŠ è½½IRå›¾åƒ
        ir_img = self.load_image(i, rgb=False)

        # åŠ è½½æ ‡ç­¾ï¼ˆåŸºäºRGBå›¾åƒè·¯å¾„ï¼‰
        label = self.labels[i].copy()

        return rgb_img, ir_img, label, self.im_files_rgb[i]

    def load_image(self, i: int, rgb: bool = True):
        """
        åŠ è½½å›¾åƒï¼ˆRGBæˆ–IRï¼‰

        Args:
            i (int): å›¾åƒç´¢å¼•
            rgb (bool): TrueåŠ è½½RGBå›¾åƒï¼ŒFalseåŠ è½½IRå›¾åƒ

        Returns:
            np.ndarray: åŠ è½½çš„å›¾åƒ (H, W, 3)
        """
        im_file = self.im_files_rgb[i] if rgb else self.im_files_ir[i]
        im = cv2.imread(im_file)  # BGR
        if im is None:
            raise FileNotFoundError(f"å›¾åƒ {im_file} æœªæ‰¾åˆ°æˆ–æŸå")

        h0, w0 = im.shape[:2]  # åŸå§‹å°ºå¯¸
        r = self.imgsz / max(h0, w0)  # ç¼©æ”¾æ¯”ä¾‹
        if r != 1:  # å¦‚æœéœ€è¦ç¼©æ”¾
            interp = cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA
            im = cv2.resize(im, (int(w0 * r), int(h0 * r)), interpolation=interp)

        return im, (h0, w0), im.shape[:2]  # å›¾åƒï¼ŒåŸå§‹å°ºå¯¸ï¼Œå½“å‰å°ºå¯¸

    def __getitem__(self, index: int):
        """
        è·å–è®­ç»ƒæ ·æœ¬

        Args:
            index (int): æ ·æœ¬ç´¢å¼•

        Returns:
            dict: åŒ…å«æ‹¼æ¥å›¾åƒå’Œæ ‡ç­¾çš„å­—å…¸
        """
        rgb_img, ir_img, label, path = self.get_image_and_label(index)

        # æ•°æ®å¢å¼º
        if self.augment:
            rgb_img, ir_img, label = self.apply_augmentations(rgb_img, ir_img, label)

        # æ‹¼æ¥RGBå’ŒIRå›¾åƒåœ¨é€šé“ç»´åº¦
        # RGB: (H, W, 3), IR: (H, W, 3) -> Combined: (H, W, 6)
        combined_img = np.concatenate([rgb_img, ir_img], axis=2)

        # è½¬æ¢ä¸ºå¼ é‡æ ¼å¼ (C, H, W)
        combined_img = combined_img.transpose(2, 0, 1)  # (6, H, W)
        combined_img = np.ascontiguousarray(combined_img)

        return {
            "img": torch.from_numpy(combined_img),
            "cls": label.get("cls", torch.empty(0)),
            "bboxes": label.get("bboxes", torch.empty(0, 4)),
            "im_file": path,
            "ori_shape": label.get("ori_shape", (combined_img.shape[1], combined_img.shape[2])),
            "resized_shape": (combined_img.shape[1], combined_img.shape[2]),
            "ratio_pad": label.get("ratio_pad", (1.0, (0.0, 0.0))),
        }

    def apply_augmentations(self, rgb_img, ir_img, label):
        """
        å¯¹RGBå’ŒIRå›¾åƒåº”ç”¨ç›¸åŒçš„å‡ ä½•å˜æ¢ï¼Œç¡®ä¿ä¸€è‡´æ€§

        Args:
            rgb_img: RGBå›¾åƒ
            ir_img: IRå›¾åƒ
            label: æ ‡ç­¾ä¿¡æ¯

        Returns:
            tuple: å¢å¼ºåçš„(rgb_img, ir_img, label)
        """
        # è¿™é‡Œå¯ä»¥å®ç°å…·ä½“çš„æ•°æ®å¢å¼ºé€»è¾‘
        # é‡è¦ï¼šRGBå’ŒIRå›¾åƒå¿…é¡»åº”ç”¨ç›¸åŒçš„å‡ ä½•å˜æ¢ï¼

        # ç¤ºä¾‹ï¼šåº”ç”¨ç›¸åŒçš„æ—‹è½¬ã€ç¿»è½¬ç­‰å˜æ¢
        if self.augment and hasattr(self, 'transforms'):
            # ç¡®ä¿å¯¹ä¸¤ä¸ªå›¾åƒåº”ç”¨ç›¸åŒçš„å˜æ¢
            pass

        return rgb_img, ir_img, label

    def update_labels_info(self):
        """æ›´æ–°æ ‡ç­¾ä¿¡æ¯ï¼Œè®¾ç½®6é€šé“è¾“å…¥"""
        super().update_labels_info()
        # é‡è¦ï¼šè®¾ç½®é€šé“æ•°ä¸º6ï¼ˆRGB 3é€šé“ + IR 3é€šé“ï¼‰
        if hasattr(self, 'data'):
            self.data['channels'] = 6

    @staticmethod
    def collate_fn(batch):
        """æ•°æ®åŠ è½½å™¨çš„æ•´ç†å‡½æ•°"""
        new_batch = {}
        for k in batch[0].keys():
            if k == "img":
                new_batch[k] = torch.stack([b[k] for b in batch], 0)
            elif k in {"cls", "bboxes"}:
                new_batch[k] = torch.cat([b[k] for b in batch], 0) if len(batch[0][k]) else torch.empty(0)
            else:
                new_batch[k] = [b[k] for b in batch]

        # æ·»åŠ æ‰¹æ¬¡ç´¢å¼•åˆ°æ ‡ç­¾
        for i, (cls, bbox) in enumerate(zip(new_batch["cls"], new_batch["bboxes"])):
            if len(cls):
                new_batch["cls"][new_batch["cls"] == cls] = i

        return new_batch


# ä¿æŒåŸæœ‰çš„YOLODatasetç±»ä»¥ç¡®ä¿å…¼å®¹æ€§
class YOLODataset(BaseDataset):
    """Dataset class for loading object detection and/or segmentation labels in YOLO format.

    ä¿æŒåŸæœ‰åŠŸèƒ½ä¸å˜...
    """
    # è¿™é‡Œä¿æŒåŸæœ‰YOLODatasetçš„å®Œæ•´å®ç°
    # [åŸå§‹ä»£ç å¤ªé•¿ï¼Œè¿™é‡Œçœç•¥ï¼Œå®é™…ä½¿ç”¨æ—¶éœ€è¦åŒ…å«å®Œæ•´çš„åŸå§‹YOLODatasetå®ç°]
    pass